{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/widsdatathon2020/training_v2.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the categorical features, binary, and numerical features in the dataset\n",
    "cat_feature = [i for i in df_train.columns.drop('hospital_death') if (df_train.dtypes[i]=='object')]\n",
    "bin_feature = [i for i in df_train.columns.drop('hospital_death') if df_train[i].isin([0.0,1.0,'nan']).all()]\n",
    "num_feature = [i for i in df_train.columns.drop('hospital_death') \n",
    "               if i not in set(cat_feature).union(set(bin_feature))\n",
    "               .union(set(['encounter_id','patient_id','hospital_id']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out highly correlated features (pearson correlation>=0.8)\n",
    "corr_mattrix = df_train[num_feature].corr()\n",
    "upper = corr_mattrix.where(np.triu(np.ones(corr_mattrix.shape),k=1).astype(bool)).abs()\n",
    "lower = corr_mattrix.where(np.tril(np.ones(corr_mattrix.shape),k=-1).astype(bool)).abs()\n",
    "to_drop_col = [i for i in upper.columns if any(upper[i]>=0.80)]\n",
    "to_drop_ind = [i for i in lower.index if any(lower[i]>=0.80)]\n",
    "print(len(to_drop_col),len(to_drop_ind),to_drop_col==to_drop_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate each highly correlated feature pairs, and find which correlated set of features has less missing values\n",
    "f_col = [e for e in to_drop_col if e not in to_drop_ind]\n",
    "f_ind = [e for e in to_drop_ind if e not in to_drop_col]\n",
    "d = {'f_col': [to_drop_col,df_train[f_col].isnull().sum().mean()],\n",
    "        'f_ind': [to_drop_ind,df_train[f_ind].isnull().sum().mean()]}\n",
    "def select_feature(d):\n",
    "    if d['f_col'][1] >= d['f_ind'][1]:\n",
    "        return d['f_col'][0]\n",
    "    else:\n",
    "        return d['f_ind'][0]\n",
    "to_drop = select_feature(d)\n",
    "# only drop those highly correlated set within the pairs of correlation matrix with less missing values as found in the previous step\n",
    "num_feature = [e for e in num_feature if e not in to_drop]\n",
    "df_train[num_feature].corr().style.background_gradient('coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df_num = pd.DataFrame(StandardScaler().fit_transform(df_train[num_feature]),columns=num_feature)\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection by calculating f-value\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "# impute missing values in x with mean of column\n",
    "X_num = SimpleImputer().fit_transform(df_num.values)\n",
    "y = df_train.hospital_death.values\n",
    "f_selector = SelectKBest(score_func=f_classif, k=15).fit(X_num,y)\n",
    "print('Sorted f-value: ', np.sort(f_selector.scores_))\n",
    "print('Sorted p-value: ', np.sort(f_selector.pvalues_))\n",
    "print('Most important features: ', df_num.columns[f_selector.pvalues_<0.05])\n",
    "print(len(df_num.columns[f_selector.pvalues_<0.05]), len(num_feature))\n",
    "# select features with p-value < 0.05\n",
    "num_feature = df_num.columns[f_selector.pvalues_<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies of cat_feature and concatenate with bin_feature\n",
    "df_cat = pd.get_dummies(df_train[cat_feature])\n",
    "# df_train[bin_feature]\n",
    "df_cat = pd.concat([df_cat,df_train[bin_feature]],axis=1)\n",
    "print(df_cat.shape)\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select categorical features by calculating chi-square\n",
    "from sklearn.feature_selection import chi2\n",
    "X_cat = SimpleImputer(strategy='most_frequent').fit_transform(df_cat.values)\n",
    "chi_selector = SelectKBest(score_func=chi2,k=15).fit(X_cat,y)\n",
    "print('Sorted chi2_value: ', np.sort(chi_selector.scores_))\n",
    "print('Sorted p-value: ', np.sort(chi_selector.pvalues_))\n",
    "print('The most important feature: ', df_cat.columns[chi_selector.pvalues_<0.05])\n",
    "print(len(df_cat.columns[chi_selector.pvalues_<0.05]), len(df_cat.columns))\n",
    "cat_feature = df_cat.columns[chi_selector.pvalues_<0.05]\n",
    "df_cat = df_cat[cat_feature]\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where cat_features have missing values, the resultant df is 90676X125\n",
    "df_model = pd.concat([df_train[['encounter_id','hospital_death']],df_num[num_feature],df_cat],axis=1)\n",
    "df_model.drop(index=df_model.index[df_model[cat_feature].isnull().any(axis=1)],inplace=True)\n",
    "print('Features that have over 70% of missing values in num_feature: ', num_feature[df_model[num_feature].isnull().sum()/len(df_model[num_feature])>0.7])\n",
    "df_model.drop(columns=num_feature[df_model[num_feature].isnull().sum()/len(df_model[num_feature])>0.7],inplace=True)\n",
    "print(df_model.shape)\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection using embedded method\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "X_model = SimpleImputer().fit_transform(df_model.drop(columns=['encounter_id','hospital_death']).values)\n",
    "y_model = df_model['hospital_death'].values\n",
    "gbm_fit = GradientBoostingClassifier(random_state=0).fit(X_model,y_model)\n",
    "zero_feature = df_model.drop(columns=['encounter_id','hospital_death']).columns[gbm_fit.feature_importances_==0]\n",
    "print('Features with zero importance: ', zero_feature)\n",
    "# drop columns in df_model with zero importance\n",
    "df_model.drop(columns=zero_feature,inplace=True)\n",
    "print(df_model.shape)\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop(columns=['encounter_id','hospital_death']).columns[rfe_fit.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features using wrapper method RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_model = SimpleImputer().fit_transform(df_model.drop(columns=['encounter_id','hospital_death']).values)\n",
    "rfe_selector = RFECV(estimator=DecisionTreeClassifier(random_state=0),min_features_to_select=15,cv=3,verbose=1,n_jobs=-1)\n",
    "rfe_fit = rfe_selector.fit(X_model,y_model)\n",
    "print('Selected features: ', df_model.drop(columns=['encounter_id','hospital_death']).columns[rfe_fit.support_])\n",
    "print('Feature ranking: ', rfe_fit.ranking_)\n",
    "X_feature = df_model.drop(columns=['encounter_id','hospital_death']).columns[rfe_fit.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "X_model = SimpleImputer().fit_transform(df_model[X_feature].values)\n",
    "best_model = {}\n",
    "model_name = ['logis','rdf','ada','gb']\n",
    "models = [LogisticRegression(solver='saga',random_state=0),\n",
    "          RandomForestClassifier(random_state=0),\n",
    "          AdaBoostClassifier(random_state=0),\n",
    "          GradientBoostingClassifier(random_state=0)]\n",
    "params = [{'penalty': ['l1','l2'],\n",
    "           'C': np.linspace(0.1,3,5)},\n",
    "          {'n_estimators': [10,100],\n",
    "           'max_features': [1,3,'auto']},\n",
    "          {'n_estimators': [10,100],\n",
    "           'learning_rate': np.linspace(0.1,3,5)}, \n",
    "          {'n_estimators': [10,100], \n",
    "           'learning_rate': np.linspace(0.1,3,5), \n",
    "           'max_features': [1,3,'auto']}]\n",
    "for i,j,k in zip(model_name,models,params):\n",
    "    grid = GridSearchCV(estimator=j,param_grid=k,scoring='roc_auc',cv=3,verbose=1,n_jobs=-1)\n",
    "    best_model[i] = grid.fit(X_model,y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best model and corresponding parameters\n",
    "best_estimator = model_name[np.argmax([best_model[i].best_score_ for i in model_name])]\n",
    "model = best_model[best_estimator].best_estimator_\n",
    "# model evaluation with cross validation\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "kf = KFold(n_splits=10,shuffle=True,random_state=0)\n",
    "cv_result = cross_val_score(estimator=model, X=X_model, y=y_model, scoring='roc_auc', cv=kf, verbose=1, n_jobs=-1)\n",
    "print('The selected model is: ', model)\n",
    "print('The score of the selected model is: ', cv_result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns==df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import unlabeled data\n",
    "df_test = pd.read_csv('/kaggle/input/widsdatathon2020/unlabeled.csv')\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict[X_feature].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing test data before prediction\n",
    "cat_feature_test = [i for i in df_test.columns.drop('hospital_death') if (df_test.dtypes[i]=='object')]\n",
    "bin_feature_test = [i for i in df_test.columns.drop('hospital_death') if df_test[i].isin([0.0,1.0,'nan']).all()]\n",
    "num_feature_test = [i for i in df_test.columns.drop('hospital_death') \n",
    "               if i not in set(cat_feature_test).union(set(bin_feature_test))\n",
    "               .union(set(['encounter_id','patient_id','hospital_id']))]\n",
    "df_num_test = pd.DataFrame(StandardScaler().fit_transform(df_test[num_feature_test]),columns=num_feature_test)\n",
    "df_num_test = df_num_test[num_feature]\n",
    "df_cat_test = pd.concat([pd.get_dummies(df_test[cat_feature_test]),df_test[bin_feature_test]],axis=1)\n",
    "df_cat_test = df_cat_test[df_cat.columns]\n",
    "df_predict = pd.concat([df_test[['encounter_id','hospital_death']],df_num_test,df_cat_test],axis=1)\n",
    "print(df_predict.shape)\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict hospital_death using adaboost and unlabeled data\n",
    "X_test = SimpleImputer().fit_transform(df_predict[X_feature].values)\n",
    "y_hat = model.predict_proba(X_test)\n",
    "df_predict['hospital_death'] = y_hat\n",
    "print(df_predict.shape)\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict[['encounter_id','hospital_death']].to_csv('submission_res.csv',index=False,float_format='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  hospital_death\n",
       "0             2               0\n",
       "1             5               0\n",
       "2             7               0\n",
       "3             8               0\n",
       "4            10               0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_pred = pd.read_csv('./submission.csv')\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
